{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sys.path.append('/home/ethanbrown/face-gen/code')\n",
    "from utils import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as F_vis\n",
    "from torchvision import transforms, datasets, io\n",
    "from torch import optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# for visualization\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image, make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Loading the data\n",
    "TRIAL_NUM = 2\n",
    "batch_size = 100\n",
    "image_size = 256\n",
    "\n",
    "gen_init_image = 8\n",
    "num_gen_features = 1024\n",
    "\n",
    "gen_learning_rate =  0.0002\n",
    "dis_learning_rate = 0.0002\n",
    "\n",
    "# Hyperparameters\n",
    "LATENT_SIZE = 200\n",
    "NUM_EPOCHS = 2500\n",
    "BETA = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save directory has more than 15 files, and so quitting to avoid overlapping.\n",
      "cuda\n",
      "Data Shape:\n",
      "torch.Size([2977, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Modifying images as needed for the size of the neural network \n",
    "DATA_PATH = '/home/ethanbrown/face-gen/data_general/data'\n",
    "\n",
    "curr_DATA_PATH = resize_images(DATA_PATH, 128, '/home/ethanbrown/face-gen/data_general/data_128')\n",
    "\n",
    "# Using colab GPU for quick training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "# DCGAN discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "   def __init__(self):\n",
    "      super(Discriminator, self).__init__()\n",
    "\n",
    "      # Convolutional block for image discrimination\n",
    "      self.conv_block = nn.Sequential(\n",
    "      nn.Conv2d(3, 8, 3, 2, 1), \n",
    "      nn.LeakyReLU(0.2), \n",
    "\n",
    "      nn.Conv2d(8, 16, 3, 2, 1), \n",
    "      nn.LeakyReLU(0.2), \n",
    "      nn.BatchNorm2d(16, 0.8),\n",
    "\n",
    "      nn.Conv2d(16, 32, 3, 2, 1), \n",
    "      nn.LeakyReLU(0.2), \n",
    "      nn.BatchNorm2d(32, 0.8),\n",
    "\n",
    "      nn.Conv2d(32, 64, 3, 2, 1), \n",
    "      nn.LeakyReLU(0.2), \n",
    "      nn.BatchNorm2d(64, 0.8),\n",
    "\n",
    "      nn.Conv2d(64, 128, 3, 2, 1), \n",
    "      nn.LeakyReLU(0.2))\n",
    "\n",
    "      # Classification layer\n",
    "      self.class_layer = nn.Sequential(nn.Linear(128 * 4 * 4, 1), nn.Sigmoid())\n",
    "\n",
    "   def forward(self, x):\n",
    "      # Resulting convolution over the image\n",
    "      out = self.conv_block(x)\n",
    "      out = out.view(out.shape[0], -1)\n",
    "      # print(out.size())\n",
    "      class_out = self.class_layer(out)\n",
    "      return class_out\n",
    "\n",
    "\n",
    "# Function to initialize weights as recommended Normal(0, 0.02)\n",
    "def weights_init(m):\n",
    "   classname = m.__class__.__name__\n",
    "   if classname.find('Conv') != -1:\n",
    "      nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "   elif classname.find('BatchNorm') != -1:\n",
    "      nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "      nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "# Function for plotting torch normalized images with matplotlib\n",
    "def prep_image(img):\n",
    "   ret_img = 0.5 *(1 + torch.permute(img, (1, 2, 0)))\n",
    "   return ret_img\n",
    "\n",
    "\n",
    "# Reading in the images in both folders\n",
    "data_matrix = []\n",
    "tensor_maker = transforms.ToTensor()\n",
    "\n",
    "list_images = os.listdir(curr_DATA_PATH)\n",
    "list_images = [x for x in list_images if x[0] != '.']\n",
    "\n",
    "for i in list_images:\n",
    "   png_img = Image.open(curr_DATA_PATH / i)\n",
    "   img_arr = tensor_maker(png_img)\n",
    "   data_matrix.append(img_arr)\n",
    "   png_img.close()\n",
    "\n",
    "# Doing some wacky stuff to get the images in the correct layout and values\n",
    "# i.e. between 0 and 1 and then making it a numpy array again so that the whole thign\n",
    "# can be a batched tensor with N, num_channels, H, W\n",
    "for i, j in enumerate(data_matrix):\n",
    "   data_matrix[i] = j.numpy()\n",
    "data_matrix = np.array(data_matrix)\n",
    "data_matrix = torch.Tensor(data_matrix)\n",
    "# Normalizing between -1  and 1 for tanh\n",
    "transform = nn.Sequential(transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)))\n",
    "data_matrix_tensor = transform(data_matrix)\n",
    "print('Data Shape:')\n",
    "print(data_matrix_tensor.shape)\n",
    "\n",
    "# Generating the dataloader\n",
    "mydata = TensorDataset(data_matrix_tensor)\n",
    "data_loader = DataLoader(mydata, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Loss function\n",
    "loss_func = torch.nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCGAN generator class\n",
    "class Generator(nn.Module):\n",
    "   def __init__(self):\n",
    "      super(Generator, self).__init__()\n",
    "\n",
    "      # Linear layer to take from the initial size to the \n",
    "      self.latent_reshape = nn.Linear(LATENT_SIZE, gen_init_image * gen_init_image * num_gen_features)\n",
    "\n",
    "      # Convolutional blocks with upsampling to increase the image size\n",
    "      self.conv_block = nn.Sequential(\n",
    "      #  8x8 input, 12x12 out\n",
    "      nn.ConvTranspose2d(in_channels=num_gen_features, out_channels=1000, kernel_size=5, stride=1, padding=1),\n",
    "      nn.BatchNorm2d(1000, 0.8),\n",
    "      nn.LeakyReLU(0.2),\n",
    "\n",
    "      # 12x12 in, 25x25 out\n",
    "      nn.ConvTranspose2d(in_channels=1000, out_channels=500, kernel_size=8, stride=3, padding=1),\n",
    "      nn.BatchNorm2d(500, 0.8),\n",
    "      nn.LeakyReLU(0.2),\n",
    "\n",
    "      # 25x25 in, 96x96 out\n",
    "      nn.ConvTranspose2d(in_channels=500, out_channels=360, kernel_size=8, stride=4, padding=2),\n",
    "      nn.BatchNorm2d(360, 0.8),\n",
    "      nn.LeakyReLU(0.2),\n",
    "\n",
    "      nn.ConvTranspose2d(in_channels=360, out_channels=3, kernel_size=5, stride=1, padding=4),\n",
    "\n",
    "      # Activation Function\n",
    "      nn.Tanh())\n",
    "\n",
    "   def forward(self, x):\n",
    "      out = self.latent_reshape(x)\n",
    "      out = out.view(out.shape[0], num_gen_features, gen_init_image, gen_init_image)\n",
    "      img = self.conv_block(out)\n",
    "      return img\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "gen = Generator().to(device)\n",
    "dis = Discriminator().to(device)\n",
    "\n",
    "# Initialize weights\n",
    "gen.apply(weights_init)\n",
    "dis.apply(weights_init)\n",
    "\n",
    "# Optimizers\n",
    "gen_optim = torch.optim.Adam(gen.parameters(), lr=gen_learning_rate, betas=(BETA, 0.999))\n",
    "dis_optim = torch.optim.Adam(dis.parameters(), lr=dis_learning_rate, betas=(BETA, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input =  torch.Size([100, 200])\n",
      "Out_linear =  torch.Size([100, 65536])\n",
      "Reshaping Size =  torch.Size([100, 1024, 8, 8])\n",
      "Image Size: torch.Size([100, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ethanbrown/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_9581/916233934.py\", line 25, in <module>\n",
      "    gen_loss.backward()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\", line 363, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 175, in backward\n",
      "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 2.34 GiB (GPU 0; 11.17 GiB total capacity; 8.12 GiB already allocated; 2.10 GiB free; 8.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ethanbrown/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ethanbrown/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ethanbrown/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ethanbrown/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/opt/conda/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/opt/conda/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9581/916233934.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m    \u001b[0;31m#Backpropagating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m    \u001b[0mgen_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m    \u001b[0mgen_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.34 GiB (GPU 0; 11.17 GiB total capacity; 8.12 GiB already allocated; 2.10 GiB free; 8.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RuntimeError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2102\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "for i, imgs in enumerate(data_loader):\n",
    "\n",
    "   # Loading in the images\n",
    "   imgs = imgs[0].to(device)\n",
    "\n",
    "   # Finding the batch_size\n",
    "   batch_size = imgs.shape[0]\n",
    "\n",
    "   # Creating the training zeros and ones\n",
    "   true = torch.ones(batch_size, 1).to(device)\n",
    "   false = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "   #######\n",
    "   # Training the generator first\n",
    "   gen_optim.zero_grad()\n",
    "   z = torch.Tensor(np.random.normal(0, 1, (imgs.shape[0], LATENT_SIZE))).to(device)\n",
    "\n",
    "   # Using the random noise\n",
    "   gen_imgs = gen(z)\n",
    "\n",
    "   # Finding the loss\n",
    "   gen_loss = loss_func(dis(gen_imgs), true)\n",
    "\n",
    "   #Backpropagating\n",
    "   gen_loss.backward()\n",
    "   gen_optim.step()\n",
    "\n",
    "   #######\n",
    "   # Now training the discriminator\n",
    "   dis_optim.zero_grad()\n",
    "\n",
    "   # Finding the discriminator loss with real and fake data\n",
    "   true_loss = loss_func(dis(imgs), true)\n",
    "   false_loss = loss_func(dis(gen_imgs.detach()), false)\n",
    "   dis_loss = (true_loss + false_loss) / 2\n",
    "\n",
    "   # Backpropagating the loss\n",
    "   dis_loss.backward()\n",
    "   dis_optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
